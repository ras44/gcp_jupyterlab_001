{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte-Carlo Version\n",
    "\n",
    "We compare `dim` statistics between two groups.  Thus, we have 2 sets of $d \\in (1,...,dim)$ auto-correlated normal distributions $\\phi_{d}=\\phi(\\mu_{d},\\sigma_{d})$.  Thus $d$ indexes a pair of distributions $A$ and $B$ that have equal variance.\n",
    "\n",
    "In order to inspect the false-positive rate and the FWER, we set the \"true\" effect to zero.  In this case we know the null hypothesis is true.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.stats.power as smp\n",
    "from scipy.linalg import cholesky\n",
    "import math\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# if using a Jupyter notebook, includue:\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set globals\n",
    "dim = 2 # the number of tests to compare\n",
    "alpha = 0.05 # the false positive rate\n",
    "power = 0.80 # 1-false negative rate\n",
    "sigma = 10  # standard deviation\n",
    "mde = 0.10  # the relative minimum detectable effect\n",
    "mu_a = 100\n",
    "mu_b = mu_a*(1+mde)\n",
    "d = (mu_b-mu_a)/sigma # standardized effect size\n",
    "n_mc = 1000  # monte-carlo trials\n",
    "corr = 0.9  # the correlation between the normal values \n",
    "\n",
    "# do power calculation for number of observations required to detect minimum detectable effect\n",
    "n_obs = math.ceil(smp.TTestIndPower().solve_power(effect_size = d, \n",
    "                                         power = power, \n",
    "                                         alpha = alpha))\n",
    "n_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.046 0.047]\n",
      "0.0465\n",
      "0.063\n"
     ]
    }
   ],
   "source": [
    "# set the true effect to 0\n",
    "effect = 0\n",
    "mu_b = (1+effect)*mu_a\n",
    "\n",
    "mean_a = mu_a*np.ones(dim)\n",
    "mean_b = mu_b*np.ones(dim)\n",
    "corr_mat = corr*np.ones([dim,dim],float)\n",
    "np.fill_diagonal(corr_mat,1.0)\n",
    "\n",
    "# Compute the (upper) Cholesky decomposition matrix\n",
    "upper_chol = cholesky(corr_mat)\n",
    "\n",
    "tts = np.empty((0,dim), int)\n",
    "ttp = np.empty((0,dim), int)\n",
    "\n",
    "for i in range(n_mc):\n",
    "    # Create two sets of dim correlated series of random values\n",
    "    v_a = np.random.normal(0.0, sigma, size=(n_obs, dim)) @ upper_chol + mean_a\n",
    "    v_b = np.random.normal(0.0, sigma, size=(n_obs, dim)) @ upper_chol + mean_b\n",
    "\n",
    "    # append dim p-values to pvs\n",
    "    ttr = scipy.stats.ttest_ind(v_a, v_b)\n",
    "    tts = np.vstack([tts, ttr.statistic])\n",
    "    ttp = np.vstack([ttp, ttr.pvalue])\n",
    "\n",
    "# Now decide to reject/not based on the simple p-value < alpha rule\n",
    "\n",
    "# Print the individual rejection rates for each test\n",
    "print(sum(ttp < alpha)/len(ttp))\n",
    "\n",
    "# Calculate the average rejection rate for all tests; if effect=0, this is the FPR\n",
    "reject_ratio = np.mean(sum(ttp < alpha)/len(ttp))\n",
    "print(reject_ratio)\n",
    "\n",
    "# Calculate the FWER\n",
    "fwer = sum(np.any(ttp<alpha, axis=1))/len(ttp)\n",
    "print(fwer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.818 0.801]\n",
      "0.8095\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# set the true effect to the mde\n",
    "effect = mde\n",
    "mu_b = (1+effect)*mu_a\n",
    "\n",
    "mean_a = mu_a*np.ones(dim)\n",
    "mean_b = mu_b*np.ones(dim)\n",
    "\n",
    "corr_mat = corr*np.ones([dim,dim],float)\n",
    "np.fill_diagonal(corr_mat,1.0)\n",
    "\n",
    "# Compute the (upper) Cholesky decomposition matrix\n",
    "upper_chol = cholesky(corr_mat)\n",
    "\n",
    "tts = np.empty((0,dim), int)\n",
    "ttp = np.empty((0,dim), int)\n",
    "\n",
    "for i in range(n_mc):\n",
    "    # Create two sets of dim correlated series of random values\n",
    "    v_a = np.random.normal(0.0, sigma, size=(n_obs, dim)) @ upper_chol + mean_a\n",
    "    v_b = np.random.normal(0.0, sigma, size=(n_obs, dim)) @ upper_chol + mean_b\n",
    "    \n",
    "    # append dim p-values to pvs\n",
    "    ttr = scipy.stats.ttest_ind(v_a, v_b)\n",
    "    tts = np.vstack([tts, ttr.statistic])\n",
    "    ttp = np.vstack([ttp, ttr.pvalue])\n",
    "\n",
    "# Now decide to reject/not based on the simple p-value < alpha rule\n",
    "# print(ttp)\n",
    "\n",
    "# Print the individual rejection rates for each test\n",
    "print(sum(ttp < alpha)/len(ttp))\n",
    "\n",
    "# Calculate the average rejection rate for all tests;\n",
    "#   if effect=0, this is the FPR\n",
    "#   if effect=mde, this is the TNR (power)\n",
    "reject_ratio = np.mean(sum(ttp < alpha)/len(ttp))\n",
    "print(reject_ratio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
